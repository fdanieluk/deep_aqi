{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:\n",
    "\n",
    "Analyse missing values, what caused them, how many of them are present in data set, how to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename, splitext\n",
    "from glob import glob\n",
    "from dask import dataframe as dd\n",
    "from matplotlib import rcParams\n",
    "import pandas as pd\n",
    "import dask\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "\n",
    "from deep_aqi import ROOT\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', 50)\n",
    "pd.set_option('max_rows', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA = join(ROOT, 'data', 'processed')\n",
    "INTERIM_DATA = join(ROOT, 'data', 'interim')\n",
    "RAW_DATA = join(ROOT, 'data', 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\users\\\\filip\\\\desktop\\\\deep_aqi\\\\deep_aqi\\\\data\\\\interim\\\\combined-WEATHER.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\fastparquet\\api.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fn, verify, open_with, root, sep)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\dask\\bytes\\local.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\users\\\\filip\\\\desktop\\\\deep_aqi\\\\deep_aqi\\\\data\\\\interim\\\\combined-WEATHER.parquet\\\\_metadata\\\\_metadata'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\dask\\dataframe\\io\\parquet.py\u001b[0m in \u001b[0;36m_read_fastparquet\u001b[1;34m(fs, fs_token, paths, columns, filters, categories, index, infer_divisions)\u001b[0m\n\u001b[0;32m    193\u001b[0m                                          \u001b[0mopen_with\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m                                          sep=fs.sep)\n\u001b[0m\u001b[0;32m    195\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\fastparquet\\api.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fn, verify, open_with, root, sep)\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\dask\\bytes\\local.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\users\\\\filip\\\\desktop\\\\deep_aqi\\\\deep_aqi\\\\data\\\\interim\\\\combined-WEATHER.parquet\\\\_metadata'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\fastparquet\\api.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fn, verify, open_with, root, sep)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\dask\\bytes\\local.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\users\\\\filip\\\\desktop\\\\deep_aqi\\\\deep_aqi\\\\data\\\\interim\\\\combined-WEATHER.parquet\\\\_metadata'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-eb59012ca788>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mweather_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINTERIM_DATA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'combined-WEATHER.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mweather\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweather_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\dask\\dataframe\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, columns, filters, categories, index, storage_options, engine, infer_divisions)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m     return read(fs, fs_token, paths, columns=columns, filters=filters,\n\u001b[1;32m-> 1153\u001b[1;33m                 categories=categories, index=index, infer_divisions=infer_divisions)\n\u001b[0m\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\dask\\dataframe\\io\\parquet.py\u001b[0m in \u001b[0;36m_read_fastparquet\u001b[1;34m(fs, fs_token, paths, columns, filters, categories, index, infer_divisions)\u001b[0m\n\u001b[0;32m    194\u001b[0m                                          sep=fs.sep)\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mpf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfastparquet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParquetFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# Validate infer_divisions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\fastparquet\\api.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fn, verify, open_with, root, sep)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\deep_aqi\\lib\\site-packages\\dask\\bytes\\local.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mNot\u001b[0m \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mukey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\users\\\\filip\\\\desktop\\\\deep_aqi\\\\deep_aqi\\\\data\\\\interim\\\\combined-WEATHER.parquet'"
     ]
    }
   ],
   "source": [
    "weather_path = join(INTERIM_DATA, 'combined-WEATHER.parquet')\n",
    "weather = dd.read_parquet(weather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.isnull().sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dew Point - f(p, T)\n",
    "\n",
    "Safe to drop; check if data not present from start, or lost in processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhdp2010_path = join(RAW_DATA, 'hourly_RH_DP_2010.csv')\n",
    "rhdp2010 = dd.read_csv(rhdp2010_path, \n",
    "                       dtype={'MDL': 'float64',\n",
    "                              'Sample Measurement': 'float64',\n",
    "                              'Qualifier': 'object'},\n",
    "                       assume_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3357945"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rhdp2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relative Humidity     3011619\n",
       "Dew Point              346326\n",
       "Name: Parameter Name, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhdp2010['Parameter Name'].value_counts().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost no values of Dew Point, drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Dew Point drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_path = join(INTERIM_DATA, 'combined-WEATHER.parquet')\n",
    "weather = dd.read_parquet(weather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiteCode                          0\n",
       "LocalDate                         0\n",
       "Wind Direction - Resultant    14326\n",
       "Wind Speed - Resultant        65437\n",
       "Outdoor Temperature               0\n",
       "Barometric pressure               0\n",
       "Relative Humidity               299\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_sites = weather.loc[weather['Wind Speed - Resultant'].isnull(), 'SiteCode'].unique().compute()\n",
    "weather.loc[weather['Wind Speed - Resultant'].isnull(), 'SiteCode'].nunique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Idaho_Benewah_11.0                                35023\n",
       "Wyoming_Sweetwater_200.0                          11427\n",
       "Massachusetts_Suffolk_42.0                         8514\n",
       "Wyoming_Fremont_99.0                               7587\n",
       "District Of Columbia_District of Columbia_43.0     1417\n",
       "Texas_Harris_1035.0                                 718\n",
       "New Hampshire_Rockingham_18.0                       284\n",
       "Wisconsin_Dodge_1.0                                 119\n",
       "Oregon_Klamath_4.0                                   93\n",
       "Kentucky_Jefferson_43.0                              76\n",
       "Maryland_Dorchester_4.0                              41\n",
       "New York_Monroe_1007.0                               36\n",
       "                                                  ...  \n",
       "Pennsylvania_Allegheny_8.0                            3\n",
       "Maryland_Washington_9.0                               3\n",
       "Maryland_Cecil_3.0                                    3\n",
       "Oregon_Union_119.0                                    3\n",
       "California_Madera_2010.0                              2\n",
       "Louisiana_East Baton Rouge_9.0                        2\n",
       "Iowa_Scott_15.0                                       2\n",
       "Maryland_Kent_2.0                                     2\n",
       "Wyoming_Teton_8.0                                     2\n",
       "Iowa_Linn_40.0                                        1\n",
       "Rhode Island_Providence_1010.0                        1\n",
       "California_Inyo_1018.0                                1\n",
       "Name: SiteCode, Length: 32, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.loc[weather['Wind Speed - Resultant'].isnull(), 'SiteCode'].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.loc[:, 'SiteCode'].nunique().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/3 of sites has NaN in Wind Speed field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.loc[weather['Wind Speed - Resultant'].isnull(), 'LocalDate'].dt.year.nunique().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaNs present across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010    25105\n",
       "2011    20699\n",
       "2013     9005\n",
       "2012     8764\n",
       "2017     1537\n",
       "2016      157\n",
       "2014      100\n",
       "2015       70\n",
       "Name: LocalDate, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.loc[weather['Wind Speed - Resultant'].isnull(), 'LocalDate'].dt.year.value_counts().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mostly in 2010 & 2011; let's see if it's present in raw file, or missing after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind2010_path = join(RAW_DATA, 'hourly_WIND_2010.csv')\n",
    "wind2010 = dd.read_csv(wind2010_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wind Direction - Resultant    8760\n",
       "Name: Parameter Name, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = (wind2010['State Name'] == 'Idaho') & (wind2010['County Name'] == 'Benewah') & (wind2010['Site Num'] == 11)\n",
    "wind2010.loc[cond, 'Parameter Name'].value_counts().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no readings of Wind Speed from this year from this station;\n",
    "\n",
    "Drop missing values, without attempt to estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiteCode                          0\n",
       "LocalDate                         0\n",
       "Wind Direction - Resultant    14326\n",
       "Wind Speed - Resultant        65437\n",
       "Outdoor Temperature               0\n",
       "Barometric pressure               0\n",
       "Relative Humidity               299\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838883911573908"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather.dropna()) / len(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop will result in lose of 1.7% of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
