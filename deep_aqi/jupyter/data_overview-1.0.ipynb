{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:\n",
    "\n",
    "Narrow down to only these sites that are valueable from analysis perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site selection\n",
    "\n",
    "Sites with 4 or more years of complete data are picked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename, splitext\n",
    "from glob import glob\n",
    "from dask import dataframe as dd\n",
    "from matplotlib import rcParams\n",
    "import pandas as pd\n",
    "import dask\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "\n",
    "from deep_aqi import ROOT\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', 50)\n",
    "pd.set_option('max_rows', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def site_code_test(table):\n",
    "    \"\"\"When files were loaded for the first time, integers were assumed missing and they were transfomed to \n",
    "    float, let's check if its consistent across all files, it could make it hard to look for same sites\n",
    "    across many files otherwise.\"\"\"\n",
    "    if table.SiteCode.str.contains('.').all():\n",
    "        pass\n",
    "        #         print('All SiteCodes have \".\" contained inside.')\n",
    "    else:\n",
    "        raise ValueError('Not all SiteCodes have \".\" contained inside!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(parameter):\n",
    "    MINIMUM_YEAR_COUNT = 4\n",
    "    files = glob(f'{INTERIM_DATA}/*.parquet', recursive=True)\n",
    "    files = [file for file in files if parameter in file]\n",
    "\n",
    "    sites = []\n",
    "    for file in files:\n",
    "        df = dd.read_parquet(file)\n",
    "        site_code_test(df)\n",
    "        sites_ = df.SiteCode.unique().compute()\n",
    "        sites.extend(sites_)\n",
    "    return set([site for site, count in Counter(sites).items() if count >= MINIMUM_YEAR_COUNT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERIM_DATA = join(ROOT, 'data', 'interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'2014': 12,\n",
       "          '2010': 12,\n",
       "          '2016': 12,\n",
       "          '2017': 12,\n",
       "          '2012': 12,\n",
       "          '2015': 12,\n",
       "          '2011': 12,\n",
       "          '2013': 12}),\n",
       " Counter({'WIND': 8,\n",
       "          '44201': 8,\n",
       "          'PRESS': 8,\n",
       "          '88502': 8,\n",
       "          '81102': 8,\n",
       "          '42602': 8,\n",
       "          'TEMP': 8,\n",
       "          '42401': 8,\n",
       "          '42101': 8,\n",
       "          'RH': 8,\n",
       "          'SPEC': 8,\n",
       "          '88101': 8}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(f'{INTERIM_DATA}/*.parquet', recursive=True)\n",
    "\n",
    "Counter([basename(file).split('_')[-1].split('.')[0] for file in files]), Counter([basename(file).split('_')[1] for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_sites = check_coverage('WIND')\n",
    "temp_sites = check_coverage('TEMP')\n",
    "press_sites = check_coverage('PRESS')\n",
    "rhdp_sites = check_coverage('RH_DP') \n",
    "\n",
    "ozone_sites = check_coverage('44201')\n",
    "sulfur_sites = check_coverage('42401') \n",
    "carbon_sites = check_coverage('42101') \n",
    "nitro_sites = check_coverage('42602')  \n",
    "\n",
    "pm25frm_sites = check_coverage('88101') \n",
    "pm10_sites = check_coverage('81102') \n",
    "pm25_sites = check_coverage('88502')  \n",
    "spec_sites = check_coverage('SPEC')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_sites = wind_sites.intersection(temp_sites).intersection(press_sites).intersection(rhdp_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ozone = weather_sites.intersection(ozone_sites)\n",
    "len(ozone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sulfur = weather_sites.intersection(sulfur_sites)\n",
    "len(sulfur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carbon = weather_sites.intersection(carbon_sites)\n",
    "len(carbon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nitro = weather_sites.intersection(nitro_sites)\n",
    "len(nitro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25frm = weather_sites.intersection(pm25frm_sites)\n",
    "len(pm25frm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm10 = weather_sites.intersection(pm10_sites)\n",
    "len(pm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25 = weather_sites.intersection(pm25_sites)\n",
    "len(pm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec = weather_sites.intersection(spec_sites)\n",
    "len(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_sites = ozone.union(sulfur).union(carbon).union(nitro).union(pm25frm).union(pm10).union(pm25).union(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(available_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('available_sites.p', 'wb') as file:\n",
    "#     pickle.dump(available_sites, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama_Jefferson_23.0',\n",
       " 'California_Fresno_5001.0',\n",
       " 'California_Kern_6001.0',\n",
       " 'California_Sacramento_11.0',\n",
       " 'California_Santa Barbara_2011.0',\n",
       " 'Colorado_Rio Blanco_5.0',\n",
       " 'Colorado_Rio Blanco_6.0',\n",
       " 'District Of Columbia_District of Columbia_43.0',\n",
       " 'Indiana_Marion_78.0',\n",
       " 'Iowa_Scott_15.0',\n",
       " 'Kentucky_Edmonson_501.0',\n",
       " 'Louisiana_East Baton Rouge_13.0',\n",
       " 'Louisiana_East Baton Rouge_9.0',\n",
       " 'Maryland_Baltimore_3001.0',\n",
       " 'Maryland_Dorchester_4.0',\n",
       " 'Maryland_Garrett_2.0',\n",
       " \"Maryland_Prince George's_30.0\",\n",
       " 'Massachusetts_Suffolk_42.0',\n",
       " 'Michigan_Kent_20.0',\n",
       " 'Michigan_Wayne_1.0',\n",
       " 'Missouri_St. Louis City_85.0',\n",
       " 'Nebraska_Douglas_19.0',\n",
       " 'Nevada_Clark_2002.0',\n",
       " 'Nevada_Clark_540.0',\n",
       " 'Nevada_Clark_75.0',\n",
       " 'New Hampshire_Hillsborough_5001.0',\n",
       " 'New Hampshire_Rockingham_18.0',\n",
       " 'New Jersey_Essex_3.0',\n",
       " 'New Mexico_Bernalillo_23.0',\n",
       " 'New York_Chautauqua_6.0',\n",
       " 'New York_Herkimer_5.0',\n",
       " 'New York_Monroe_1007.0',\n",
       " 'North Carolina_Mecklenburg_41.0',\n",
       " 'North Dakota_Burke_4.0',\n",
       " 'North Dakota_Cass_1004.0',\n",
       " 'Ohio_Hamilton_40.0',\n",
       " 'Ohio_Preble_1001.0',\n",
       " 'Oregon_Multnomah_80.0',\n",
       " 'Pennsylvania_Allegheny_8.0',\n",
       " 'Rhode Island_Providence_1010.0',\n",
       " 'Tennessee_Sevier_101.0',\n",
       " 'Texas_El Paso_55.0',\n",
       " 'Texas_Harris_1035.0',\n",
       " 'Texas_Harris_24.0',\n",
       " 'Texas_Harris_416.0',\n",
       " 'Texas_Jefferson_1035.0',\n",
       " 'Texas_Tarrant_3009.0',\n",
       " 'Vermont_Bennington_4.0',\n",
       " 'Vermont_Chittenden_7.0',\n",
       " 'Virginia_Madison_3.0',\n",
       " 'Washington_King_80.0',\n",
       " 'Wisconsin_Dodge_1.0',\n",
       " 'Wyoming_Fremont_99.0',\n",
       " 'Wyoming_Laramie_100.0',\n",
       " 'Wyoming_Sublette_99.0',\n",
       " 'Wyoming_Sweetwater_200.0',\n",
       " 'Wyoming_Sweetwater_300.0',\n",
       " 'Wyoming_Teton_8.0'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_aqi",
   "language": "python",
   "name": "deep_aqi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
